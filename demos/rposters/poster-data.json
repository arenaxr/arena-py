[
  {
    "email": "jmiller4@andrew.cmu.edu",
    "name": [
      "John Miller"
    ],
    "authors": "",
    "title": "Android Team Awareness Kit (ATAK) XR",
    "abstract": "In this project, we will integrate CONIX Web XR and localization technologies with the civilian Android Team Awareness Kit (ATAK) software platform to enable augmented reality visualization support in GPS-denied environments. CONIX localization technologies uses UWB ranging radios that are fused with VIO already available on Android phones to provide accurate 60Hz 6-DOF tracking and have already demonstrated the ability to track the full pose of mobile devices to within 10 centimeters in 3D space allowing them display pass-through AR information that is tightly registered in the physical environment.",
    "poster": "",
    "demo": true,
    "theme": 1,
    "photo": "https://conix.io/wp-content/uploads/photos/37.JPG",
    "video": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "avideo": "",
    "advisor": "Anthony Rowe",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14435/"
    ],
    "gdate": "2022-05-09T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mefe106ffc97e861d6d31132377ed25c6"
  },
  {
    "email": "gtfierro@cs.berkeley.edu",
    "name": [
      "Gabe Fierro",
      "Dezhi Hong"
    ],
    "authors": "Gabe Fierro, Jason Koh, Dezhi Hong",
    "title": "Self-Adapting Software for Smart Cities and Buildings",
    "abstract": "We will demonstrate the execution of analytics and visualizations (hopefully integrated with ARENA VR) that are written *once* and then deployed over a collection of real buildings, which are all different. The emphasis is on the programmability of these resources: how is it that software can use Brick to query the necessary metadata in order to customize its operation automatically for the particular resources/configurations for each building. Will include web dashboards, VR experience (we're thinking pseudo-live temperature heat maps of multiple buildings) and an exploration of how self-adapting software can be written.",
    "poster": "",
    "demo": true,
    "theme": 1,
    "photo": "https://conix.io/wp-content/uploads/photos/29.png",
    "video": "",
    "avideo": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "advisor": "David Culler;Rajesh Gupta",
    "school": "University of California, Berkeley",
    "schoolshort": "Berkeley",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14320/",
      "https://www.src.org/student-center/student-directory/15310/"
    ],
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mefe106ffc97e861d6d31132377ed25c6"
  },
  {
    "email": "maluc@g.ucla.edu",
    "name": [
      "Marcus Lucas",
      "Luigi Pannocchi",
      "Lucas Fraile"
    ],
    "authors": "Marcus Lucas, Luigi Pannocchi, Lucas Fraile",
    "title": "Infrastructure Configuration and Interaction via AR",
    "abstract": "This demo illustrates how Augmented Reality (AR) systems can be leveraged to assist in the inspection, configuration, and deployment of CONIX-enabled infrastructure. In this instance, a human operator uses a virtual interface to connect sensing and computational resources to a quadrotor which they subsequently control via the same interface. In addition, the interface is capable of displaying real-time information related to said infrastructure, including the network topology, latency, computational loads, and uncertainty in position estimates. This information can be used by the human operator to reconfigure a designated system on-the-fly. We envision this demo as providing a reference example for multidomain applications, which will eventually be enhanced by integrating work from other CONIX researchers.",
    "poster": "",
    "demo": true,
    "theme": 1,
    "photo": "https://conix.io/wp-content/uploads/lll.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Paulo Tabuada",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14095/",
      "https://www.src.org/student-center/student-directory/15590/",
      "https://www.src.org/student-center/student-directory/14094/"
    ],
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mefe106ffc97e861d6d31132377ed25c6"
  },
  {
    "email": "mclarkk@berkeley.edu",
    "name": [
      "Meghan Clark"
    ],
    "authors": "",
    "title": "XRShark: Mixed Reality Network Introspection",
    "abstract": "Poster for the Distributed RF Spectrum Sensing DSSP.",
    "poster": "",
    "demo": true,
    "theme": 1,
    "photo": "https://conix.io/wp-content/uploads/photos/55.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Prabal Dutta",
    "school": "University of California, Berkeley",
    "schoolshort": "Berkeley",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14613/"
    ],
    "gdate": "2019-05-18T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mefe106ffc97e861d6d31132377ed25c6"
  },
  {
    "email": "harshd@andrew.cmu.edu",
    "name": [
      "Harsh Desai"
    ],
    "authors": "Harsh Desai, Brandon Lucia",
    "title": "A flock of Camaropteras",
    "abstract": "Ultra-low-power, energy-harvesting image sensors enable ubiquitous sensing applications like CONIX Smart Cities. In this demo, we extend the previously presented Camaroptera device by firstly deploying a new and improved prototype, and secondly combining multiple Camaroptera image sensors into a larger system. We deploy this team, or a \"flock\", of Camaroptera devices in an outdoor environment, where we tackle the challenge of coordinating multiple energy-harvesting image sensors with a common basestation, where each device does not work under input power guarantees. Lastly, we combine our Camaroptera flock with  an online resource manager to demonstrate a AR-based real-time navigation system, where a user can \"fast-forward\" themselves to different locations along the route and preview the current scene at the corresponding locations.",
    "poster": "",
    "demo": true,
    "theme": 2,
    "photo": "https://conix.io/wp-content/uploads/photos/192.jpg",
    "video": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "avideo": "",
    "advisor": "Brandon Lucia",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15498/"
    ],
    "gdate": "2024-05-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48014712a83df58749a6b5851f6c87fc"
  },
  {
    "email": "eruppel@andrew.cmu.edu",
    "name": [
      "Emily Ruppel"
    ],
    "authors": "Emily Ruppel and Brandon Lucia",
    "title": "Peripheral Management for Resource-Constrained Computing Systems",
    "abstract": "The CONIX smart cities application includes highly resource constrained sensing and computing devices for which programmers must manage miniscule energy budgets.  Peripheral sensors and actuators are significant sources of extraneous energy consumption on these devices, but reducing peripheral power requires expert programmers intimately familiar with the application requirements and hardware.  This poster presents Pudu, a peripheral management analysis and runtime system that reduces energy consumption of sensing and computing workloads with minimal programmer involvement. Pudu uses a simple set of annotations to track changes in peripheral operating mode throughout a program. \n Pudu then automatically inserts peripheral management code that will reduce the program’s total energy consumption.  Pudu decreases application energy by an average of 13% across a suite of 420 benchmark configurations, with energy reductions of up to 45%.  We also apply Pudu in a full application case study where complex sensing and processing applications execute intermittently using harvested energy, and we find that Pudu reduces energy (and execution time) to nearly the level of an idealized point of comparison",
    "poster": "",
    "demo": true,
    "theme": 2,
    "photo": "https://conix.io/wp-content/uploads/photos/34.png",
    "video": "",
    "avideo": "",
    "advisor": "Brandon Lucia",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14125/"
    ],
    "gdate": "2021-12-20T05:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mf7152147bc8cc5469430f54323fdcd7f"
  },
  {
    "email": "nbehari@andrew.cmu.edu",
    "name": [
      "Nikhil Behari"
    ],
    "authors": "Nikhil Behari, Franceska Xhakaj, Amy Ogan, Chris Harrison",
    "title": "Intelligent Interfaces for Classroom Nonverbal Behavior Monitoring",
    "abstract": "Pedagogical research, especially regarding university instructors, indicates that classroom nonverbal behaviors are critical for encouraging and maintaining student engagement. Movement, gesturing, and eye contact, for example, may help establish instructor credibility and positively impact student learning ability. However, it is difficult for instructors to observe and engage with data on their nonverbal behavior during lectures, currently requiring expert monitoring or extensive knowledge of classroom immediacy literature. In this research, we develop an accessible, intelligent interface to help instructors view and engage with data on their teaching nonverbal behavior. Using EduSense, a comprehensive monitoring tool that detects relevant features of classroom behavior in real-time, we develop a front-end platform that 1) Introduces key classroom behavior metrics to instructors, 2) Visualizes data outputs from the EduSense pipeline, and 3) Produces intelligent recommendations to help improve instructor nonverbal behavior. We also provide a portal for researchers to view platform engagement metrics and customize interface settings to support user testing. This research furthers development for the EduSense distributed system, building upon computer vision and machine learning techniques for broad scale classroom sensing. ",
    "poster": "https://docs.google.com/presentation/d/1BbqaRCbBxN9XEKBcamY5KTBnixvJvYrK_PWfGhmAsxw/edit?usp=sharing",
    "demo": true,
    "theme": 2,
    "photo": "https://conix.io/wp-content/uploads/photos/217.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Chris Harrison",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": "",
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48014712a83df58749a6b5851f6c87fc"
  },
  {
    "email": "chejmadi@andrew.cmu.edu",
    "name": [
      "Chinmay Hejmadi"
    ],
    "authors": "Chinmay Hejmadi",
    "title": "Edusense Audio Processing Pipeline",
    "abstract": "This poster describes the audio processing pipeline of the Edusense project at Carnegie Mellon University. This project carries out practical classroom sensing in order to aid the professional development of teachers and educators. Our aim is to extract audio-visual features from classes that can provide real-time feedback to teachers on the impact of their teaching, much like how a FitBit sensor reports step count to an end user app. ",
    "poster": "https://docs.google.com/presentation/d/1uD90XBjlObG7584OncLDxoRn6CrfVd6Tbr0w5KDCD8s/edit?usp=sharing",
    "demo": true,
    "theme": 1,
    "photo": "https://conix.io/wp-content/uploads/photos/213.jpeg",
    "video": "",
    "avideo": "",
    "advisor": "Chris Harrison",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": "",
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mf7152147bc8cc5469430f54323fdcd7f"
  },
  {
    "email": "devals@andrew.cmu.edu",
    "name": [
      "Deval Shah"
    ],
    "authors": "Deval Shah, Karan Ahuja, Chris Harrison",
    "title": "Where they are looking?",
    "abstract": "This work comes under the project Edusense, a practical classroom sensing at scale. Two cameras facing each other in a classroom do not give information about where the students/instructors are looking. This work aims to address the issue and converts the classroom to a 3D virtual space. This helps identify where students and instructors spend their time looking in a classroom setup i.e. whiteboard, podium, laptop/tablet etc. ",
    "poster": "https://drive.google.com/drive/folders/1TKxGEFYRpDiqDf9lRzIwWg1G4EeqBi2G?usp=sharing",
    "demo": true,
    "theme": 1,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Chris Harrison",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": "",
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48014712a83df58749a6b5851f6c87fc"
  },
  {
    "email": "ketakisrao@outlook.com",
    "name": [
      "Ketaki Rao"
    ],
    "authors": "",
    "title": "Professional development of university level professors using classroom data obtained from sensing technologies.",
    "abstract": "Edusense is a sensing system that utilizes cameras and microphones among other sensors to get data from a university level lecture. We gather this data and analyze it to deliver specific insights to professors/lecturers/educators who want to or are in need of professional development.",
    "poster": "",
    "demo": true,
    "theme": 1,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Chris Harrison",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": "",
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mf7152147bc8cc5469430f54323fdcd7f"
  },
  {
    "email": "neal.jackson@berkeley.edu",
    "name": [
      "Neal Jackson"
    ],
    "authors": "Neal Jackson, Prabal Dutta",
    "title": "Eternacam: A Wireless Camera Sensor Platform for Multi-Year Indoor Computer Vision Applications",
    "abstract": "Deploying widespread computer vision applications indoors is traditionally burdened by costly installation and maintenance. Cameras are generally power intensive and thus necessitate wired connections. This limits placement options, coverage, and potential applications. Wireless, battery-powered cameras exist, but generally do not last longer than a few weeks or months without battery replacement or recharging. This severely hinders the permanence and usefulness of indoor computer vision applications.\n\nIn this paper, we present Eternacam, a wireless camera sensor platform with a multi-year lifetime. Eternacam combines energy harvesting with a traditional battery to last  half a decade when configured to capture images every ten minutes in an indoor environment. The platform is capable of performing local image inference like person classification and transmitting images end-to-end.",
    "poster": "",
    "demo": true,
    "theme": 2,
    "photo": "https://conix.io/wp-content/uploads/photos/19.jpg",
    "video": "",
    "avideo": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "advisor": "Prabal Dutta",
    "school": "University of California, Berkeley",
    "schoolshort": "Berkeley",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14395/"
    ],
    "gdate": "2021-05-12T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48014712a83df58749a6b5851f6c87fc"
  },
  {
    "email": "jaybosamiya@cmu.edu",
    "name": [
      "Jay Bosamiya"
    ],
    "authors": "Jay Bosamiya, Benjamin Lim, Bryan Parno",
    "title": "WebAssembly as an Intermediate Language for Provably-Safe Software Sandboxing",
    "abstract": "Lightweight, safe, and fast execution of untrusted code is valuable in many contexts and can, in theory, be achieved via software fault isolation (SFI). Unfortunately, technological and marketplace hurdles have prevented mass adoption of previous SFI technologies. We propose to use WebAssembly to overcome these hurdles. Conceretely, we describe ongoing work on a formally verified sandboxing compiler, from WebAssembly to native code, towards this goal.",
    "poster": "https://www.src.org/library/publication/p101313/",
    "demo": true,
    "theme": 3,
    "photo": "https://conix.io/wp-content/uploads/photos/97.jpg",
    "video": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "avideo": "",
    "advisor": "Bryan Parno",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14625/"
    ],
    "gdate": "2022-08-15T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m0f6c3a704d64a918eb50430ac4b08729"
  },
  {
    "email": "lisa.masserova@gmail.com",
    "name": [
      "Elisaweta Masserova"
    ],
    "authors": "Vipul Goyal, Abhiram Kothapalli, Elisaweta Masserova, Bryan Parno, Yifan Song ",
    "title": "Storing and Retrieving Secrets on a Blockchain",
    "abstract": "In our work we propose a blockchain protocol that enables storing secret data and subsequently retrieving the data if specified conditions have been met. This construction enables a number of exciting applications (time-lock encryption, one-time programs etc.), which previously existed only as theoretical designs.",
    "poster": "https://www.src.org/library/publication/p101301/",
    "demo": true,
    "theme": 3,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Bryan Parno",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15995/"
    ],
    "gdate": "2023-06-30T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48b33e6a5e6b1e5ac799ba95d3b51ace"
  },
  {
    "email": "akothapa@andrew.cmu.edu",
    "name": [
      "Abhiram Kothapalli"
    ],
    "authors": "Abhiram Kothapalli, Lisa Masserova, Bryan Parno, Vipul Goyal",
    "title": "Engineering Faster Verifiable Computation",
    "abstract": "We build techniques to efficiently outsource computation to the cloud and verify that the returned results are correct.",
    "poster": "https://www.src.org/library/publication/p101315/",
    "demo": true,
    "theme": 3,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Bryan Parno",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14949/"
    ],
    "gdate": "2023-05-19T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m0f6c3a704d64a918eb50430ac4b08729"
  },
  {
    "email": "ddchen@andrew.cmu.edu",
    "name": [
      "Daming D Chen"
    ],
    "authors": "Daming Chen, Wen Shih Lim, Mohammad Bakhshalipour, Phillip Gibbons, James C. Hoe, Bryan Parno",
    "title": "HerQules: Securing Programs via Hardware-Enforced Message Queues",
    "abstract": "Programs are commonly partitioned to provide security guarantees. However, software-based mechanisms for intra-process isolation suffer from significant overhead, compatibility issues, or rely on security through obscurity. Existing hardware-based mechanisms, on the other hand, are highly complex and require significant microarchitectural changes, as a result of implementing too much functionality in hardware.\n\nInstead, we propose a simple and fast AppendWrite interprocess communication (IPC) primitive for append-only messages, which allows security policies to rely on much stronger inter-process isolation properties. Based on this primitive, we design HerQules, a framework for implementing efficient integrity-based security policies. HerQules decouples program execution from policy checking by performing both concurrently, which reduces overhead on the critical path. We build low-cost implementations of AppendWrite for an FPGA-based accelerator and in the microarchitecture, which we validate using simulation. We perform a case study on control- flow integrity using a benchmark suite of programs, demonstrating that HerQules achieves a significant improvement in correctness, effectiveness, and performance compared to prior work.",
    "poster": "https://www.src.org/library/publication/p101287/",
    "demo": true,
    "theme": 3,
    "photo": "https://conix.io/wp-content/uploads/photos/209.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Bryan Parno",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/16019/"
    ],
    "gdate": "2021-05-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48b33e6a5e6b1e5ac799ba95d3b51ace"
  },
  {
    "email": "scauligi@eng.ucsd.edu",
    "name": [
      "Sunjay Cauligi and Craig Disselkoen"
    ],
    "authors": "Sunjay Cauligi and Craig Disselkoen",
    "title": "Defending Applications from Spectre with Entry-Point Analysis",
    "abstract": "Large applications like the Chrome web browser are usually composed of several different processes. Web pages are rendered in subprocesses while the main process keeps secret data, like your browser cookies. This design provides important security guarantees: even if an attacker is able to fully control a renderer process, they can’t compromise the main process. However, due to a recently discovered attack called Spectre, it's possible for an attacker to get the main process to unintentionally reveal secret information, such as your cookies.\n\nOur key insight is that an attacker only has influence over a small number of entry points to the application. We can perform static taint tracking to find all of these places and scalably and efficiently defend software such as browsers and operating systems using only a small number of defenses.",
    "poster": "https://docs.google.com/presentation/d/13InBEHn-aN9aV9zIvjSyB2kmo449AChw7QqHkomNjsM/edit?usp=sharing",
    "demo": true,
    "theme": 3,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Deian Stefan",
    "school": "University of California, San Diego",
    "schoolshort": "UCSD",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14606/"
    ],
    "gdate": "2021-06-11T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m0f6c3a704d64a918eb50430ac4b08729"
  },
  {
    "email": "mmccorm1@andrew.cmu.edu",
    "name": [
      "Matt McCormack"
    ],
    "authors": "Matt McCormack, Guyue Liu, Amit Vasudevan, Sanjay Chandrasekaran, Tianlong Yu, Sebastian Echeverria,  Grace Lewis,  Vyas Sekar",
    "title": "Aegis: Trusted Architecture for Securing IoT Devices at the Edge",
    "abstract": "Many studies have pointed out security problems with   IoT deployments. Given the diversity of devices and the lack of concerted efforts from device manufacturers to adopt best practices,   recent efforts have recommended  pragmatic  ``bolt on'' security gateways at the network layer to secure  IoT deployments using software-defined principles. \nWhile such gateways are an  attractive option, they also raise a paradoxical concern: \\emph{can the gateway itself be trusted?}. This is especially pertinent in light of attacks on these software-defined architectures;   e.g.,  traffic bypassing the gateway  or exploiting vulnerabilities in the software-defined control frameworks managing these gateways.   \n\nThis paper presents \\textsc{Jetfire}, a practical, low-cost architecture solution with built-in trust for software-defined security gateways. In designing and  implementing \\textsc{Jetfire}, we make three key contributions: (1)  A practical and deployable  basis for trust leveraging a micro-hypervisor based system architecture to ensure packets output by the gateway are processed by the appropriate network security policy; (2) A scalable low-cost implementation  to support fine-grained per-device policies; and (3) A formal  analysis of threats and demonstration that our architecture provides defenses by construction. \nWe demonstrate that \\textsc{Jetfire} provides intrinsic security against a broad spectrum of attacks including 9  published attacks against such software-defined architectures. We show that \\textsc{Jetfire} can provide low-cost security;  e.g., a \\$35 Raspberry Pi can effectively support custom per-device IPS instances for a small IoT deployment of up to 57 devices. We also validate on two representative IoT deployments of a smart home and a smart manufacturing facility. ",
    "poster": "",
    "demo": true,
    "theme": 3,
    "photo": "https://conix.io/wp-content/uploads/photos/90.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Vyas Sekar",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14610/"
    ],
    "gdate": "2020-08-31T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48b33e6a5e6b1e5ac799ba95d3b51ace"
  },
  {
    "email": "yyin4@andrew.cmu.edu",
    "name": [
      "Yucheng Yin"
    ],
    "authors": "Yucheng Yin, Alan Liu, Grace Liu, Vyas Sekar",
    "title": "Trustworthy Sketch-based Measurement in Software Switches",
    "abstract": "The poster is about building a trustworthy sketch-based monitoring system in software switches.",
    "poster": "",
    "demo": true,
    "theme": 3,
    "photo": "https://conix.io/wp-content/uploads/photos/154.JPG",
    "video": "",
    "avideo": "",
    "advisor": "Vyas Sekar",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15603/"
    ],
    "gdate": "2023-05-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m0f6c3a704d64a918eb50430ac4b08729"
  },
  {
    "email": "zaoxingliu@gmail.com",
    "name": [
      "Alan (Zaoxing) Liu"
    ],
    "authors": "",
    "title": "Jaqen: High-Performance Switch-Native DDoS Defense with Programmable Switches",
    "abstract": "This work fits the themes of security and hardware platform within CONIX: Programmable switches provide an opportunity to revisit network-layer defenses  for volumetric DDoS attacks as they offer better cost vs. performance vs. flexibility trade-offs relative to proprietary hardware  and virtual appliances. Existing efforts, however, have fundamental problems as they rely on inaccurate out-of-band detection techniques and offer limited and inefficient mitigation capabilities. To tackle these challenges, we design and implement Jaqen, a switch-native approach for performant and flexible  DDoS defense using programmable switches.  We implement a broad spectrum of DDoS  detection and mitigation modules in a resource-efficient manner and provide fast response as attack postures change. Our experiments show that Jaqen is orders of magnitude more performant than existing systems: Jaqen can handle large-scale hybrid and dynamic attacks within seconds, and mitigate them effectively at high line-rates (400 Gbps). ",
    "poster": "",
    "demo": true,
    "theme": 3,
    "photo": "https://conix.io/wp-content/uploads/photos/171.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Vyas Sekar",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15420/"
    ],
    "gdate": "2020-10-31T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48b33e6a5e6b1e5ac799ba95d3b51ace"
  },
  {
    "email": "tianli@cmu.edu",
    "name": [
      "Tian Li"
    ],
    "authors": "Tian Li, Maziar Sanjabi, Ahmad Beirami, Virginia Smith",
    "title": "Fair Resource Allocation in Federated Learning",
    "abstract": "Federated learning is a privacy-preserving paradigm learning for learning in heterogeneous networks, with many mobile/wireless applications. We propose a novel optimization objective that encourages fairness in heterogeneous federated networks, and develop a scalable method to solve it.",
    "poster": "",
    "demo": true,
    "theme": 3,
    "photo": "https://conix.io/wp-content/uploads/photos/173.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Virginia Smith",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14981/"
    ],
    "gdate": "2023-06-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m0f6c3a704d64a918eb50430ac4b08729"
  },
  {
    "email": "mkolosick@eng.ucsd.edu",
    "name": [
      "Matthew Kolosick"
    ],
    "authors": "Matthew Kolosick, Shravan Narayan, Deian Stefan, Conrad Watt, and Deepak Garg",
    "title": "Zero Cost Transitions for In-Process Isolation, SFI, and WebAssembly",
    "abstract": "In-process component isolation techniques such as WebAssembly, Native Client, and Intel Memory Protection Keys allow applications to securely run untrusted code. These techniques provide an appealing alternative to placing components in separate operating system processes: they replace the expensive remote procedure calls (RPC) between processes with lightweight, in-process function calls while providing equivalent security.\nDespite the elimination of RPCs, existing systems must nevertheless perform a version of the inter-process context switch; failing to do so would compromise the security of component isolation. These in-process context switches clear scratch registers, switch stacks, and save and restore registers on transitions to prevent malicious or compromised components from reading secret data stored in scratch registers or corrupting the trusted application by breaking the calling-convention. Unfortunately the cost of these operations can become a performance bottleneck—for instance, context switches impose an 800% overhead when using a sandboxed font rendering library in the Firefox browser.\nIn this paper we demonstrate conditions that let us safely eliminate the in-process context switch operations, resulting in secure Zero-Cost Transitions that completely eliminate the above 800% overhead. To ensure that the new technique is secure we formalize a model that captures component isolation context switching and define transition-related security properties. We then use this model to formally define the zero-cost conditions and prove that our Zero-Cost Transition system provides the same security guarantees as the in-process con- text switches. We demonstrate that WebAssembly naturally meets these conditions and implement Zero-Cost Transitions in a WebAssembly-based component isolation system.\n\nThis work fits within Conix's Secure Programming and Trustworthy Programming tasks as it enables efficient (and therefore broadly usable) sandboxing. The formal model ensures that the speedups maintain security so that we may rely on the same guarantees from our faster transition technique.",
    "poster": "https://www.src.org/library/publication/p101314/",
    "demo": true,
    "theme": 3,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Deian Stefan",
    "school": "University of California, San Diego",
    "schoolshort": "UCSD",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15979/"
    ],
    "gdate": "2023-06-16T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m48b33e6a5e6b1e5ac799ba95d3b51ace"
  },
  {
    "email": "e5johnso@eng.ucsd.edu",
    "name": [
      "Evan Johnson"
    ],
    "authors": "Evan Johnson, David Thien, Yousef Alhessi, Shravan Narayan, Fraser Brown, Tyler McMullen, Sorin Lerner,  Stefan Savage, Deian Stefan",
    "title": "Trust, but verify: SFI safety for native-compiled Wasm",
    "abstract": "Subtle bugs in Wasm compilers can misplace safety checks or remove them when it is not safe to do so, breaking isolation guarantees. To address this problem, we propose verifying memory isolation of Wasm binaries post-compilation. We implement this approach in VeriWasm, a small, static verifier for native x86-64 binaries compiled from Wasm; we prove the verifier's soundness, and find that it can detect bugs and with no false positives (so far). \n",
    "poster": "",
    "demo": true,
    "theme": 3,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Deian Stefan",
    "school": "University of California, San Diego",
    "schoolshort": "UCSD",
    "srcprofile": "",
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m0f6c3a704d64a918eb50430ac4b08729"
  },
  {
    "email": "wangsj@uw.edu",
    "name": [
      "Shengjie Wang"
    ],
    "authors": "Shengjie Wang, Tianyi Zhou, Jeff A. Bilmes",
    "title": "Using Dynamic Instance Hardness to Guide the Learning Process",
    "abstract": "A good teacher can adjust a curriculum based on students' learning history. By analogy, in this paper, we study the dynamics of a deep neural network's (DNN) performance on individual samples during its learning process. This allows us to develop an adaptive curriculum that leads to faster learning of more accurate models. We introduce {\\it dynamic instance hardness} (DIH), the exponential moving average of a sample's instantaneous hardness (e.g., a loss, or a change in outputs) over the training history. A low DIH indicates that a model retains knowledge about a sample over time, and implies a flat loss landscape for that sample. Moreover, we find that a sample's DIH early in training predicts its DIH in later stages. Hence, we can train a model using samples with higher DIH and safely ignore those with lower DIH. This motivates a DIH guided curriculum learning strategy (DIHCL). Compared to existing CL methods: (1) DIH is more stable over time than using only instantaneous hardness, which is noisy due to stochastic training and DNN's non-smoothness; (2) DIHCL is computationally inexpensive since it uses only a byproduct of back-propagation and thus does not require extra inference. On 11 datasets, DIHCL significantly outperforms random mini-batch SGD and recent CL methods in terms of efficiency and final performance. For learning on a network, DIHCL can produce a curriculum for selecting training samples to send across devices, resulting in reduced network traffic and better performance.",
    "poster": "",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/172.jpg",
    "video": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "avideo": "",
    "advisor": "Jeff Bilmes",
    "school": "University of Washington",
    "schoolshort": "UW",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15309/"
    ],
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfa5854a601ee8a69dd62356acb451a6f"
  },
  {
    "email": "tianyizh@uw.edu",
    "name": [
      "Tianyi Zhou"
    ],
    "authors": "Tianyi Zhou, Shengjie Wang, Jeff A. Bilmes",
    "title": "Time-Consistent Self-Supervision for Semi-Supervised Learning",
    "abstract": "Semi-supervised learning (SSL) leverages unlabeled data when training a model with insufficient labeled data. A common strategy for SSL is to enforce the consistency of model outputs between similar samples, e.g., neighbors or data augmentations of the same sample. However, model outputs can vary dramatically on unlabeled data over different training stages, e.g., when using large learning rates. This can introduce harmful noises and inconsistent objectives over time that may lead to concept drift and catastrophic forgetting. In this paper, we study the dynamics of neural net outputs in SSL and show that selecting and using first the unlabeled samples with more consistent outputs over the course of training (i.e., \"time-consistency\") can improve the final test accuracy and save computation. Under the time-consistent data selection, we design an SSL objective composed of two self-supervised losses, i.e., a consistency loss between a sample and its augmentation, and a contrastive loss encouraging different samples to have different outputs. Our approach achieves SOTA on several SSL benchmarks with much fewer computations.",
    "poster": "https://docs.google.com/presentation/d/1c5s_q6YrVNDnjkIVWLz0Xl1I-ID0IsErMM9AKL7sqFM/edit#slide=id.p",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/77.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Jeff Bilmes",
    "school": "University of Washington",
    "schoolshort": "UW",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14477/"
    ],
    "gdate": "2019-09-05T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfc95e0301fbb88b594ad3b95f171e591"
  },
  {
    "email": "lkumari@uw.edu",
    "name": [
      "Lilly Kumari"
    ],
    "authors": "Lilly Kumari, Jeff Bilmes",
    "title": "Submodular Span, with Application to Conditional Data Summarization",
    "abstract": "As an extension to matroid span, we propose a new task called the submodular span problem that involves finding a large set of data items redundant to a given query set.  We then propose a two stage Submodular Span Summarization (S3) framework to achieve a form of conditional data summarization.  The first stage encourages the summary to be relevant to a given query set, and the second stage encourages the final summary to be both diverse and non-redundant, thus meeting the two important criteria for a good query-focused summary.  Unlike previous methods, the S3 framework uses only a single submodular function defined over both data and query.  We analyze theoretical properties in the context of both matroids and polymatroids that help to elucidate how and when our methods should work well. We find that a scalable approximation algorithm to the polymatroid submodular span has good theoretical and empirical properties. We provide empirical and qualitative results on three real-world tasks: conditional multi-document summarization on the DUC 2005-2007 datasets, conditional video summarization on the UT-Egocentric datasets, and conditional summarization on the ImageNet dataset. Also, we employ this method in multi-streaming and network video summarization tasks to generate conditional summary of live video feeds.",
    "poster": "",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/188.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Jeff Bilmes",
    "school": "University of Washington",
    "schoolshort": "UW",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15412/"
    ],
    "gdate": "2023-08-06T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfa5854a601ee8a69dd62356acb451a6f"
  },
  {
    "email": "lavaniac@uw.edu",
    "name": [
      "Chandrashekhar Lavania"
    ],
    "authors": "Chandrashekhar Lavania and Jeff Bilmes",
    "title": "Asymmetric Autoencoders",
    "abstract": "Autoencoders have seen extensive use in dimensionality reduction procedures. At their core is an encoder-decoder architecture. The encoder is responsible for the transformation of data into a low dimensional space and thus it also acts as a compressor, while the decoder recovers an approximation of the original and thus acts as a decompressor.  This work takes inspiration from a property of compression/decompression, i.e., that compression is often much more computationally difficult than decompression (this is true, for example, in popular compression tools such as zip, gzip, bzip2, and xz), and that  compression time is monotonically related to the compression ratio. Based on this, we propose highly asymmetric autoencoders.  We propose end-to-end learning of autoencoders with a heavy and deep encoder and a single-layer non-negative decoder. Several tasks, including non-negative dictionary learning, data storage, and the representation learning of features for summarization can benefit from their use.  These autoencoders are also valuable for efficient communication and processing of data flowing in the network. The single-layer decoder requires extremely low resources for transforming the encoded data to its original space, thereby reducing the computational burden network nodes.",
    "poster": "",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/143.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Jeff Bilmes",
    "school": "University of Washington",
    "schoolshort": "UW",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/12915/"
    ],
    "gdate": "2019-06-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfc95e0301fbb88b594ad3b95f171e591"
  },
  {
    "email": "vikranth94@g.ucla.edu",
    "name": [
      "J. Vikranth Jeyakumar"
    ],
    "authors": "Jeya Vikranth Jeyakumar, Ludmila Cherkasova, Mani Srivastava",
    "title": "Combining Individual and Joint Networking Behavior for Intelligent IoT Analytics",
    "abstract": "The IoT vision of a trillion connected devices over the next decade requires reliable end-to-end connectivity and automated device management platforms. While we have seen successful efforts for maintaining small IoT testbeds,  there are multiple challenges for the efficient management of large-scale device deployments. With Industrial IoT, incorporating millions of devices, traditional management methods do not scale well. In this work, we address these challenges by designing a set of novel machine learning techniques, which form a foundation of a new tool, IoTelligent, for IoT device management, using traffic characteristics obtained at the network level. \nThe design of our tool is driven by the analysis of 1-year long networking data, collected from 350 companies with IoT deployments. The exploratory analysis of this data reveals that IoT environments follow the famous Pareto principle, such as: (i) 10% of the companies in the dataset contribute to 90% of the entire traffic; (ii) 7% of all the companies in the set own 90% of all the devices. We designed and evaluated CNN, LSTM, and Convolutional LSTM models for demand forecasting,  with a conclusion of the Convolutional LSTM model being the best. However, maintaining and updating individual company models is expensive. In this work, we design a novel, scalable approach, where a general demand forecasting model is built using the combined data of all the companies with a normalization factor. Moreover, we introduce a novel technique for device management, based on autoencoders. They automatically extract relevant device features to identify device groups with similar behavior to flag anomalous devices.",
    "poster": "",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/119.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Mani Srivastava",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14665/"
    ],
    "gdate": "2022-03-20T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfa5854a601ee8a69dd62356acb451a6f"
  },
  {
    "email": "swapnilsayan@g.ucla.edu",
    "name": [
      "Swapnil Sayan Saha"
    ],
    "authors": "Swapnil Sayan Saha, Sandeep Singh Sandha and Mani Srivastava",
    "title": "Robust Deep Learning Pipeline in the Presence of Runtime Sensing Uncertainties",
    "abstract": "Internet-of-Things frameworks can be regarded as a large-scale heterogeneous multimodal sensing system consisting of edge and cloud devices making rich inferences from big-data. However, challenges of handling data in the wild include missing samples, misaligned data timestamps across sensors, and variations in sampling rates. In this project, we introduce a robust training pipeline that handles sampling rate variability, missing data, and misaligned data timestamps from noisy multimodal sensors using intelligent data augmentation techniques. Specifically, we use controlled jitter in window length and add artificial misalignments in data timestamps between sensors, along with masking meta-data representations and pop-ahead samples for missing data. We evaluate the proposed pipeline on the Cooking Activity Dataset with Macro and Micro Activities, benchmarking the performance of deep convolutional bidirectional long short-term memory (DCBL) classifier, as well as for multimodal fusion for smartphone sensors. In our evaluations, the proposed pipeline improves complex activity recognition accuracy from 11-24% over vanilla approaches, while smartphone multimodal fusion can handle timing errors of upto 600ms.",
    "poster": "https://www.src.org/library/publication/p101298/",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/211.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Mani Srivastava",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/16148/"
    ],
    "gdate": "2024-06-14T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfc95e0301fbb88b594ad3b95f171e591"
  },
  {
    "email": "sandha@cs.ucla.edu",
    "name": [
      "Sandeep Singh Sandha"
    ],
    "authors": "Sandeep Singh Sandha, Mohit Aggarwal, Igor Fedorov,  Mani Srivastava",
    "title": "Mango Ver-2: Parallel Hyperparameter Tuning across ML Classifiers",
    "abstract": "Mango is a python library for parallel optimization over complex search spaces. Mango enables the use of arbitrary distributed scheduling frameworks, implements intelligent parallel search strategies, and provides rich abstractions for defining complex hyperparameter search spaces that are compatible with scikit-learn. Mango is available open-source and is currently used in production at Arm Research to provide state-of-art hyperparameter tuning capabilities. In this poster, we will discuss the next developments of Mango that are focussed on providing parallel search across a set of classifiers.  ",
    "poster": "https://drive.google.com/file/d/11hxTecLDoG5comIQzVnYxrZC-ghkxdV1/view?usp=sharing",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/179.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Mani Srivastava",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15182/"
    ],
    "gdate": "2019-02-21T05:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfa5854a601ee8a69dd62356acb451a6f"
  },
  {
    "email": "samurdhi@g.ucla.edu",
    "name": [
      "Samurdhi Karunaratne"
    ],
    "authors": "Samurdhi Karunaratne, Samer Hanna, Danijela Cabric",
    "title": "Training Better Authorization Systems by Mimicking RF Transmitter Fingerprints using Machine Learning",
    "abstract": "With the rise of the Internet of Things (IoT), ensuring the security of smart cities that depend on IoT devices is of paramount importance. To satisfy the limited computational and power budget of such devices, machine-learning based passive physical layer transmitter authorization systems have been introduced recently. These systems generally rely on the hardware fingerprints of wireless transmitters to differentiate between a given set of authorized transmitters and to sieve out unauthorized transmitters. In this project, we demonstrate that neural networks are capable of mimicking such hardware fingerprints in a variety of settings. First, we show that given a dataset of wireless signals captured from authorized transmitters, variational autoencoders could be used to generate 1). more authorized samples and 2. samples from transmitters other than those in the authorized set (unauthorized samples). This is extremely useful for training more accurate classifiers for authorization. Next, by using reinforcement learning techniques, we show that unauthorized transmitters can add carefully learned perturbations to their transmitted signals to mimic authorized transmitters, thereby allowing them to fool standard deep-learning based transmitter authorization systems with high rates of success. We supplement this by showing that pre-training authorization classifiers with adversarial samples obtained using classical methods improves their robustness against such impersonators.",
    "poster": "",
    "demo": true,
    "theme": 4,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Danijela Cabric",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/16056/"
    ],
    "gdate": "2021-03-19T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfc95e0301fbb88b594ad3b95f171e591"
  },
  {
    "email": "yitaoh@usc.edu",
    "name": [
      "Yitao Hu"
    ],
    "authors": "Yitao Hu, Weiwu Pang, Xiaochen Liu, Rajrup Ghosh, Ramesh Govindan",
    "title": "D2: AutoScaling GPUs in the Cloud",
    "abstract": "With the development of deep learning (DL) and 5G techniques, it is common to offload DL workload to the cloud. The cloud provider will be responsible to auto-scale resources according to the incoming dynamic workload. Meanwhile, the cloud provider also aims to increase its throughput with a variety of sharing strategies. We designed a GPU cloud serving system, called D2, which is able to adjust resource allocation to changes in workload, as well as to serve more requests than traditional sharing strategies with the same amount of resources. Preliminary experiment results show that D2 can respond to workload changes within 10 seconds, and double the throughput with the same amount of resources while still achieving the latency SLO.",
    "poster": "https://www.src.org/library/publication/p101316/",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/68.png",
    "video": "",
    "avideo": "",
    "advisor": "Ramesh Govindan",
    "school": "University of Southern California",
    "schoolshort": "USC",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14621/"
    ],
    "gdate": "2019-07-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfa5854a601ee8a69dd62356acb451a6f"
  },
  {
    "email": "vtolani@berkeley.edu",
    "name": [
      "Varun Tolani"
    ],
    "authors": "Varun Tolani, Somil Bansal, Aleksandra Faust, Claire Tomlin",
    "title": "Visual Navigation Among Humans With Optimal Control as a Supervisor",
    "abstract": "Real world navigation requires robots to operate in unfamiliar, dynamic environments, sharing spaces with humans. Navigating around humans is especially difficult because it requires predicting their future motion, which can be quite challenging. We propose a novel framework for navigation around humans which combines learning-based perception with model based optimal control. Specifically, we train a Convolutional Neural Network (CNN)-based perception module which maps the robot’s visual inputs to a waypoint, or next desired state. This waypoint is then input into planning and control modules which convey the robot safely and efficiently to the goal. To train the CNN we contribute a photo-realistic bench-marking dataset for autonomous robot navigation in the presence of humans. The CNN is trained using supervised learning on images rendered from our photo-realistic dataset. The proposed framework learns to anticipate and react to peoples’ motion based only on a monocular RGB image, without explicitly\npredicting future human motion. Our method generalizes well to unseen buildings and humans in both simulation and real world environments. Furthermore, our experiments demonstrate that combining model-based control and learning leads to better and more data-efficient navigational behaviors as compared to a\npurely learning based approach. Videos describing our approach and experiments are available on the project website:\n\nhttps://smlbansal.github.io/LB-WayPtNav-DH/\n\nThis work fits into CONIX theme 4 (Machine Learning) and theme 5 (Communication, Position, and Control) as it directly blends tools from optimal control theory with machine learning techniques for perception.",
    "poster": "https://www.src.org/library/publication/p101308/",
    "demo": true,
    "theme": 4,
    "photo": "https://conix.io/wp-content/uploads/photos/221.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Claire Tomlin",
    "school": "University of California, Berkeley",
    "schoolshort": "Berkeley",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15534/"
    ],
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=mfa5854a601ee8a69dd62356acb451a6f"
  },
  {
    "email": "enesk@g.ucla.edu",
    "name": [
      "Enes Krijestorac"
    ],
    "authors": "Enes Krijestorac, Samer Hanna, Danijela Cabric",
    "title": "Deep Learning Model-based UAV Access Point Placement",
    "abstract": "Mobile devices such as unmanned aerial vehicles (UAVs) can optimize their location in order to maximize the signal strength to a base station or user equipment on the ground. Various placement optimizations algorithms for signal strength have been proposed to solve for optimal placement of such UAVs. Model-based solutions rely on being able to predict the signal  strength across the optimization space and use that to find the optimal path to maximize the signal strength. At the heart of model-based solutions is some type of spatial signal strength prediction algorithm. Inspired by the successes of artificial neural networks in physics modeling, we use deep neural networks to predict the radio signal strength field in an urban environment. Our algorithm relies on samples of signal strength collected across the prediction space and a 3D map of the environment, which enables it to predict the scattering of radio waves through the environment. We demonstrate how the signal strength prediction algorithm can be used for UAV placement with signal strength measurements collected by a sensor network or by the UAV as it explores a new environment. ",
    "poster": "",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/169.jpg",
    "video": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "avideo": "",
    "advisor": "Danijela Cabric",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14695/"
    ],
    "gdate": "2023-05-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m7f0296c2cd2d3f41e9b263b0fb32898c"
  },
  {
    "email": "samerhanna@ucla.edu",
    "name": [
      "Samer Hanna"
    ],
    "authors": "Samer Hanna, Danijela Cabric",
    "title": "Towards Distributed Beamforming from UAV Swarms ",
    "abstract": "Unmanned aerial vehicles (UAVs) are a critical component of CONIX driver applications. Their mobility allows them to support situational awareness scenarios or provide services in a smart city.  Communication is an integral component for the UAVs to perform their tasks. To overcome their power constraints, UAVs need to cooperate to extend their communication range. By implementing distributed beamforming, the UAVs  can act as a single antenna array boosting the transmitted power, thus extending the communication range. However, to achieve this goal, the UAVs need to synchronize their signals over the air. In this year’s demo, we scaled up the demonstration to work with up to 4 beamforming software defined radios. The robustness of the setup was improved to make it work at various signal-to-noise ratios and under radio mobility.",
    "poster": "",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/142.jpg",
    "video": "",
    "avideo": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "advisor": "Danijela Cabric",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14693/"
    ],
    "gdate": "2023-06-30T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m919ae213a09d7a36a7e23401892c873e"
  },
  {
    "email": "matthew_g_anderson@berkeley.edu",
    "name": [
      "Matthew Anderson"
    ],
    "authors": "Matthew Anderson,  Ali Niknejad, Jan Rabaey",
    "title": "IC Design For Ultra-Power Beamforming Using Transmission-Line Transformers",
    "abstract": "Building on our previous work, in which we outlined a novel fully passive technique for RF beamforming technique utilizing transmission-line transformers and tuned passives, we present the details of our new fully-passive 4-element 12 GHz beamforming RFIC. By creating a fully passive beamforming front end solution, we hope to drastically reduce the power and cost of receiving mmWave phased array systems.",
    "poster": "",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/85.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Jan Rabaey",
    "school": "University of California, Berkeley",
    "schoolshort": "Berkeley",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14475/"
    ],
    "gdate": "2020-05-11T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m7f0296c2cd2d3f41e9b263b0fb32898c"
  },
  {
    "email": "wangzq312@g.ucla.edu",
    "name": [
      "Ziqi Wang"
    ],
    "authors": "Ziqi Wang, Zhe Chen, Akash Deep Singh, Luis Garcia, Jun Luo and Mani B. Srivastava",
    "title": "UWHear: Through-wall Extraction and Separation of Audio Vibrations Using Wireless Signals",
    "abstract": "An ability to detect, classify, and localize complex acoustic events can be a powerful tool to help smart systems build context-awareness, e.g., to make rich inferences about human behaviors in physical spaces. Conventional methods to measure acoustic signals employ microphones as sensors. As signals from multiple acoustic sources are blended during propagation to a sensor, such methods impose a dual challenge of separating the signal for an acoustic event from background noise and from other acoustic events of interest. Recent research has proposed using radio-frequency (RF) signals, e.g., Wi-Fi and millimeter-wave (mmWave), to sense sound directly from source vibrations. Whereas these works allow separating an acoustic event from background noise, they cannot monitor multiple sound sources simultaneously. In this paper, we present UWHear, a system that simultaneously recovers and separates sounds from multiple sources.\nUnlike previous works using continuous-wave RF, UWHear employs Impulse Radio Ultra-Wideband (IR-UWB) technology, in order to construct an enhanced audio sensing system tackling the above challenges, and also to be robust in non-line-of-sight (NLOS) conditions. In addition to providing a theoretical guarantee for audio recovery using RF pulses, we also implement an audio sensing prototype exploiting a commercial-off-the-shelf IR-UWB radar. Our experiments show that UWHear can effectively separate multiple sounds whose sources are placed only 25cm apart, while sensing sound source vibrations in an adjacent room a few meters behind a wall.",
    "poster": "https://www.src.org/library/publication/p101302/",
    "demo": true,
    "theme": 2,
    "photo": "https://conix.io/wp-content/uploads/photos/175.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Mani Srivastava",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15183/"
    ],
    "gdate": "2023-06-16T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m919ae213a09d7a36a7e23401892c873e"
  },
  {
    "email": "akashdeepsingh@g.ucla.edu",
    "name": [
      "Akash Deep Singh"
    ],
    "authors": "Akash Deep Singh, Luis Garcia, Joseph Noor, Mani Srivastava",
    "title": "I Always Feel Like Somebody's Sensing Me! A Framework to Detect, Identify, and Localize Clandestine Wireless Sensors",
    "abstract": "The increasing ubiquity of low-cost wireless sensors in smart homes and buildings has enabled users to easily deploy systems to remotely monitor and control their environments. However, this raises privacy concerns for third-party occupants, such as a hotel room guest who may be unaware of deployed clandestine sensors. Previous methods focused on specific modalities such as detecting cameras but do not provide a generalizable and comprehensive method to capture arbitrary sensors which may be \"spying\" on a user. In this work, we seek to determine whether one can walk in a room and detect any wireless sensor monitoring an individual. As such, we propose SnoopDog, a framework to not only detect wireless sensors that are actively monitoring a user, but also classify and localize each device. SnoopDog works by establishing causality between patterns in observable wireless traffic and a trusted sensor in the same space, e.g., an inertial measurement unit (IMU) that captures a user's movement. Once causality is established, SnoopDog performs packet inspection to inform the user about the monitoring device. Finally, SnoopDog localizes the clandestine device in a 2D plane using a novel trial-based localization technique. We evaluated SnoopDog across several devices and various modalities and were able to detect causality 96.6% percent of the time, classify suspicious devices with 100% accuracy, and localize devices to a sufficiently reduced sub-space. ",
    "poster": "https://drive.google.com/file/d/1TSCqZYtPEix-xl_qxb7bqolngWpXs6Ag/view?usp=sharing",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/135.jpeg",
    "video": "",
    "avideo": "",
    "advisor": "Mani Srivastava",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14757/"
    ],
    "gdate": "2023-06-15T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m7f0296c2cd2d3f41e9b263b0fb32898c"
  },
  {
    "email": "lfrailev@g.ucla.edu",
    "name": [
      "Lucas M Fraile"
    ],
    "authors": "Lucas M Fraile, Luigi Pannochi, Paulo Tabuada",
    "title": "Data-Driven Control for Multiple Input Multiple Output Systems",
    "abstract": "We address the challenge of controlling an unknown multiple-input multiple-output nonlinear system without using prior data or training. This work was inspired by the vision of a plug-and-play architecture that supports the control of unknown devices provided they expose information about their inputs and outputs. In this poster we illustrate our methodology to fully control a quad-copter, allowing the user to specify high-level instructions such as set-points or desired trajectories over the Arena platform. This exemplifies scenarios in which users discover assets with unknown dynamical characteristics and that can be instantly controlled, via Arena, without the need to learn a dynamical model.",
    "poster": "",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/145.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Paulo Tabuada",
    "school": "University of California, Los Angeles",
    "schoolshort": "UCLA",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14094/"
    ],
    "gdate": "2022-06-30T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m919ae213a09d7a36a7e23401892c873e"
  },
  {
    "email": "hangqiu@usc.edu",
    "name": [
      "Hang Qiu"
    ],
    "authors": "",
    "title": "AutoCast: Scalable Cooperative Perception for Autonomous Vehicles",
    "abstract": "Autonomous driving and advanced driving assistance systems use 3D sensors for perception. In cooperative perception, vehicles share sensor readings with each other to improve safety. Sharing requires significant bandwidth resources. AutoCast enables scalable cooperative perception using vehicle-to-vehicle  communication by carefully determining which objects to share based on positional relationships between traffic participants, and the time evolution of their trajectories. It casts this as Markov decision process optimization formulation amenable to dynamic programming, but because these scheduling decisions have to be made at fine timescales, AutoCast uses near-optimal greedy heuristic which maximizes the utility of the transmitted information. To demonstrate completeness and feasibility, AutoCast develops sensor processing algorithms to extract objects rapidly, and trajectory planning algorithms that can make use of additional perspectives received from other vehicles.\n\n We have implemented AutoCast on Carla, a photorealistic autonomous driving simulator. Extensive evaluation results under different scenarios show that AutoCast is able to avoid crashes and near-misses which occur frequently without cooperative perception, its transmission schedules can be completed on the real radio testbed, and its scheduling algorithm is near-optimal with negligible computation overhead, delivering 2 to 3X more useful information compared to sharing in a random order. ",
    "poster": "https://www.src.org/library/publication/p101297/",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/26.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Ramesh Govindan",
    "school": "University of Southern California",
    "schoolshort": "USC",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14413/"
    ],
    "gdate": "2019-05-10T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m7f0296c2cd2d3f41e9b263b0fb32898c"
  },
  {
    "email": "weiwupan@usc.edu",
    "name": [
      "Weiwu Pang"
    ],
    "authors": "Weiwu Pang, Ziqi Wang, Akash Deep Singh, Ramesh Govindan and Mani Srivastava",
    "title": "Panoptes: Real-time 3D Modeling of Large Urban Spaces",
    "abstract": "Panoptes’ goal is to be able to get complete, near-real time 3D situational awareness of urban environments. It will provide significant military and civilian applicability by stressing both compute and communication.",
    "poster": "",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/132.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Ramesh Govindan",
    "school": "University of Southern California",
    "schoolshort": "USC",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14737/"
    ],
    "gdate": "2023-05-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m919ae213a09d7a36a7e23401892c873e"
  },
  {
    "email": "weiwupan@usc.edu",
    "name": [
      "Weiwu Pang"
    ],
    "authors": "Weiwu Pang, Christina Shin, Fawad Ahmad, Pradipta Ghosh, Ramesh Govindan",
    "title": "Pedestrian Tracking with Infrastructure-based Sensors",
    "abstract": "A system with infrastructure-based sensors that can detect and track pedestrians.",
    "poster": "https://www.src.org/library/publication/p101305/",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/132.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Ramesh Govindan",
    "school": "University of Southern California",
    "schoolshort": "USC",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14737/"
    ],
    "gdate": "2023-05-01T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m919ae213a09d7a36a7e23401892c873e"
  },
  {
    "email": "esoltana@andrew.cmu.edu",
    "name": [
      "Elahe Soltanaghaei"
    ],
    "authors": "Elahe Soltanaghaei, Akarsh Prabhakara, Artur Balanuta, Matthew Anderson, Swarun Kumar, Anthony Rowe",
    "title": "Millimetro: mmWave Retro-Reflective Tags for Accurate, Long Range Localization",
    "abstract": "We present Millimetro, an ultra-low-power tag that can be localized at high accuracy over extended distances. We develop Millimetro in the context of autonomous driving to efficiently localize roadside infrastructure such as lane markers and road signs, even if obscured from view, where visual sensing fails. While RF-based localization offers a natural solution, current ultra-low-power localization systems struggle to operate accurately at extended ranges under strict latency requirements. Millimetro addresses this challenge by re-using existing automotive radars that operate at mmWave frequency where plentiful bandwidth is available to ensure high accuracy and low latency. We address the crucial free space path loss problem experienced by signals from the tag at mmWave bands by building upon Van Atta Arrays that retro-reflect incident energy back towards the transmitting radar with minimal loss and low power consumption. Our experimental results indoors and outdoors demonstrate a scalable system that operates at a desirable range (over 100 m), accuracy (centimeter-level), and ultra-low-power (< 3 uW).",
    "poster": "",
    "demo": true,
    "theme": 5,
    "photo": "https://conix.io/wp-content/uploads/photos/199.png",
    "video": "",
    "avideo": "",
    "advisor": "Anthony Rowe",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15601/"
    ],
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m7f0296c2cd2d3f41e9b263b0fb32898c"
  },
  {
    "email": "sylvia.herbert@berkeley.edu",
    "name": [
      "Sylvia Herbert"
    ],
    "authors": "Sylvia Herbert, Claire Tomlin",
    "title": "Safe Real-World Autonomy in Uncertain and Unstructured Environments",
    "abstract": "Overview of work in enabling efficient and safe decision-making in complex autonomous systems, while reasoning about uncertainty in real-world environments, including those involving human interactions. ",
    "poster": "",
    "demo": true,
    "theme": 5,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Claire Tomlin",
    "school": "University of California, Berkeley",
    "schoolshort": "Berkeley",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14605/"
    ],
    "gdate": "2020-06-03T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m919ae213a09d7a36a7e23401892c873e"
  },
  {
    "email": "jianfenw@usc.edu",
    "name": [
      "Jianfeng Wang"
    ],
    "authors": "Jianfeng Wang (USC), Zhuojin Li (USC), Tamas Levai (Budapest University of Technology and Economics), Marcos Vieira (Federal University of Minas Gerais), Barath Raghavan (USC), Ramesh Govindan (USC)",
    "title": "Bridging The Gap Between FaaS and NFV",
    "abstract": "Network Functions (NFs) are important processing tasks on raw packets. Platforms running NFs need to be highly efficient while serving dynamic traffic. Function-as-a-Service (FaaS) is an emerging cloud computing service that handles the provisioning, executing and scaling of user-defined functions. Conceptually, NFs can benefit from the just-in-demand scalability offered by FaaS. However, we find that today’s FaaS platforms are not well-suited for running NFs in many aspects, such as user-interface, efficiency, and performance. In this work, we answer the question: what is the set of changes to make a FaaS platform suitable for deploying NFs? We develop a FaaS platform called FaaS-NFV and show that it can efficiently meet performance and isolation requirements of running NFs.",
    "poster": "https://www.src.org/library/publication/p101303/",
    "demo": false,
    "theme": 5,
    "photo": "#N/A",
    "video": "",
    "avideo": "",
    "advisor": "Ramesh Govindan",
    "school": "University of Southern California",
    "schoolshort": "USC",
    "srcprofile": [
      ""
    ],
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m7f0296c2cd2d3f41e9b263b0fb32898c"
  },
  {
    "email": "zzhao1@andrew.cmu.edu",
    "name": [
      "Zhipeng Zhao"
    ],
    "authors": "Zhipeng Zhao, Hugo Sadok, Nirav Atre, James C. Hoe, Vyas Sekar, Justine Sherry",
    "title": "Pigasus: Achieving 100Gbps Intrusion Prevention on a Single Server",
    "abstract": "Intrusion Detection and Prevention Systems (ID/PS) are among the most demanding stateful network functions. Today's network operators are faced with securing 100Gbps networks with 100K+ concurrent connections by deploying ID/PSes to search for 10K+ rules concurrently. In this project, we set an ambitious goal: Can we do all of the above in a single server? Through the Pigasus ID/PS, we show that this goal is achievable, perhaps for the first time, by building on recent advances in FPGA-capable SmartNICs. Pigasus' design takes an FPGA-first approach, where the majority of processing, and all state and control flow are managed on the FPGA. However, doing so requires careful design of algorithms and data structures to ensure fast common-case performance while densely utilizing system memory resources. Our experiments with a variety of traces show that Pigasus can support 100Gbps using an average of 12 cores and 1 FPGA, using 25x less wattage than a CPU-only approach. This work shows an important use-case that can benefit from computing in network, which is aligned with CONIX's goal of pushing intelligence into the network.",
    "poster": "https://www.src.org/library/publication/p101312/",
    "demo": true,
    "theme": 6,
    "photo": "https://conix.io/wp-content/uploads/photos/39.jpg",
    "video": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "avideo": "https://www.youtube.com/watch?v=7BaafBt80Bc",
    "advisor": "James Hoe",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14120/"
    ],
    "gdate": "2019-12-19T05:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m11db4b7fa3151049d3cdea20ea7340a6"
  },
  {
    "email": "edge-rm@googlegroups.com",
    "name": [
      "Josh Adkins",
      "Joseph Noor",
      "Botong Ou"
    ],
    "authors": "Josh Adkins, Joseph Noor, Botong Ou, Prabal Dutta, Mani Srivastava",
    "title": "A Resource Manager for the Heterogeneous Edge",
    "abstract": "Today, creating an IoT application, even a simple one, requires the programming or management of clusters of compute nodes ranging from lightweight, embedded devices to server-class machines, each with their own system interface and domain expertise. This process is slow, not conducive to experimentation, and has a high barrier to entry for experts and non-experts alike. While compute frameworks such as Hadoop's MapReduce, Apache Spark, and Kubernetes have significantly lowered the barrier to entry to utilizing once similarly untenable clusters of servers, their gains cannot be directly extended to the IoT space because their resource managers and schedulers are not suited for the heterogeneity of the edge computing environment.\n\nThis work demonstrates a first effort to design a resource management framework suitable for the range of networking topologies, compute and memory constraints, system interfaces, and resources that are found in an edge computing environment. Like Apache Mesos, the proposed architecture aggregates and offers resources to schedulers wishing to schedule a sensing, compute or actuation task, but the notion of a resource, how resources are expected to change, and how tasks are executed are modified to handle this heterogeneity. We show the success of this method by creating several example compute frameworks that use the new resource manager to interactively schedule tasks on sensor, gateway, and server nodes, and this demo allows one to write programs using our frameworks and see how tasks are decomposed and distributed across several edge computing clusters deployed in our homes.",
    "poster": "",
    "demo": true,
    "theme": 6,
    "photo": "https://conix.io/wp-content/uploads/jjb.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Mani Srivastava; Prabal Dutta",
    "school": "University of California Los Angeles/University of California Berkeley",
    "schoolshort": "UCLA; Berkeley",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/13359/",
      "https://www.src.org/student-center/student-directory/14315/",
      "https://www.src.org/student-center/student-directory/15715/"
    ],
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m69443d0eb6f0e8dd09cf8fb7c0616fcc"
  },
  {
    "email": "kaufmans@cs.washington.edu",
    "name": [
      "Samuel J. Kaufman"
    ],
    "authors": "Samuel J. Kaufman & Rastislav Bodik",
    "title": "Kriek: An IR for Multiscale Tensor Program Optimization",
    "abstract": "Efficient tensor programs on modern accelerators are carefully designed to exploit each level of the compute hierarchy, with special attention paid to the coordination of memory movement. This is challenging even for the relatively small number of developers with expertise in this kind of performance engineering, and the performance gap between an expert programmer and a compiler ranges from 2x to 100x. However, recent work has demonstrated that program synthesis techniques can discover state-of-the-art program implementations, though these techniques do not scale  to programs larger than an individual operator. To leverage these techniques at the scale of entire tensor programs, we propose a novel intermediate representation (IR) called Kriek which decomposes programs into fully independent sub-programs across the compute hierarchy and explicitly schedules memory movements. In this IR, code can be generated for these sub-programs manually (e.g. leveraging cuBLAS), using a default code generator, or, when tractable, with synthesis. The goal of Kriek is to generate tensor programs as efficient as those which, today, can only be written by hand.\n\nThis project supports CONIX Themes 6.1, & 6.2 by introducing a unifying abstraction for high-performance scheduling of tensor applications onto heterogeneous compute targets, including edge devices employed by Theme 1 projects.",
    "poster": "",
    "demo": true,
    "theme": 6,
    "photo": "https://conix.io/wp-content/uploads/photos/214.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Ramesh Govindan",
    "school": "University of Southern California",
    "schoolshort": "USC",
    "srcprofile": "",
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m11db4b7fa3151049d3cdea20ea7340a6"
  },
  {
    "email": "krzysd@cs.washington.edu",
    "name": [
      "Krzysztof Drewniak"
    ],
    "authors": "Krzysztof Drewniak, Maaz Bin Safeer Ahmad, and Rastislav Bodik",
    "title": "Developing Accelerator Kernels that use Irregular Data Movement Strategies with Program Synthesis",
    "abstract": "Hardware accelerators, such as GPUs and vector co-processors (for example, Qualcomm's HVX), are key tools for obtaining  high performance for mathematical operations. These optimized kernels underpin the fast execution of machine learning and vision models, which are used throughout the CONIX driver applications, both on edge devices and in more central locations. One reason creating programs that take full advantage of these accelerators is difficult is that efficient kernel implementations often require complex data access and movement patterns, or swizzles, that existing state-of-the-art compilers cannot discover.  While expert programmers can produce high-quality algorithms by hand, the process is labor-intensive.  Therefore, we have developed Swizzleflow, a tool that helps developers program accelerators using program synthesis. With Swizzleflow, programmers can provide a high-level sketch of their algorithm and have our search process (which incorporates novel synthesis techniques) find a way to complete it that ensures the final code is correct. We have used Swizzleflow to synthesize kernels for GPUs that match or outperform the state of the art and rediscover swizzles found in handwritten HVX programs, which shows its portability and utility.",
    "poster": "https://www.src.org/library/publication/p101295/",
    "demo": true,
    "theme": 6,
    "photo": "https://conix.io/wp-content/uploads/photos/177.jpg",
    "video": "",
    "avideo": "",
    "advisor": "Ramesh Govindan",
    "school": "University of Southern California",
    "schoolshort": "USC",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15298/"
    ],
    "gdate": "2024-06-14T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m69443d0eb6f0e8dd09cf8fb7c0616fcc"
  },
  {
    "email": "newcombj@cs.washington.edu",
    "name": [
      "Julie L. Newcomb"
    ],
    "authors": "Julie L. Newcomb, Shoaib Kamil, Andrew Adams, Ras Bodik",
    "title": "Verifying and Improving Halide’s Term Rewriting System with Program Synthesis",
    "abstract": "Halide is a domain-specific language for high-performance image processing and tensor computations, widely adopted in industry. Internally, the Halide compiler relies on a term rewriting system to prove properties of code required for efficient and correct compilation.  This rewrite system is a collection of handwritten transformation rules that incrementally rewrite expressions into simpler forms; the system requires high performance in both time and memory usage to keep compile times low. In this work, we apply formal techniques to prove the correctness of existing rewrite rules and provide a guarantee of termination. Then, we build an automatic program synthesis system that operates over the undecidable theory of integers in order to craft new, provably correct rules from failure cases where the compiler was unable to prove properties. We show our synthesis procedure can find bug fixes equal or better than human-authored patches; and synthesize a large body of new rules without human oversight which show performance gains over even the mature Halide compiler. We also offer some observations on integerating formal methods with the Halide developers' workflow. This work should be of interest to compiler authors as well as those who seek to optimize machine learning, vision, and graphics pipelines.",
    "poster": "",
    "demo": true,
    "theme": 6,
    "photo": "https://conix.io/wp-content/uploads/photos/80.png",
    "video": "",
    "avideo": "",
    "advisor": "Ramesh Govindan",
    "school": "University of Southern California",
    "schoolshort": "USC",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14409/"
    ],
    "gdate": "2020-05-22T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m11db4b7fa3151049d3cdea20ea7340a6"
  },
  {
    "email": "mds009@eng.ucsd.edu",
    "name": [
      "Michael Smith"
    ],
    "authors": "",
    "title": "Just-in-time checking for just-in-time compilers",
    "abstract": "We present Proton, a framework for checking browser JIT output in order to find JIT bugs. Proton allows developers to write traditional translation validation passes—e.g., to prove that register allocation preserves program semantics—as well as static-style checkers—e.g., to check that Spectre mitigations aren’t missing. We implement Proton and a suite of five checkers and verifiers in Rust in the Firefox browser. Most checkers cause almost no slowdown, but Proton gives developers fine-grained control over when and how to apply expensive checkers. Proton uncovered an underlying design flaw in the JIT’s Spectre mitigations that’s been confirmed by Firefox developers, and Firefox is integrating Proton into their fuzzing infrastructure.",
    "poster": "",
    "demo": true,
    "theme": 6,
    "photo": "",
    "video": "",
    "avideo": "",
    "advisor": "Deian Stefan",
    "school": "University of California, San Diego",
    "schoolshort": "UCSD",
    "srcprofile": "",
    "gdate": "",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m69443d0eb6f0e8dd09cf8fb7c0616fcc"
  },
  {
    "email": "qijing.huang@berkeley.edu",
    "name": [
      "Qijing Jenny Huang"
    ],
    "authors": "Qijing Huang, Zhen Dong, Dequan Wang, Kurt Keutzer, John Wawrzynek",
    "title": "Efficient Deployment of Input-adaptive ObjectDetection on FPGAs",
    "abstract": "Deploying deep learning models on embedded systems for computer vision tasks has been challenging due to limited compute resources and strict energy budgets.\nThe majority of existing work focuses on accelerating image classification, \nwhile other fundamental vision problems, such as object detection, \nhave not been adequately addressed. Compared with image classification, \ndetection problems are more sensitive to the spatial variance of objects, \nand therefore, require specialized convolutions to aggregate spatial information. \nTo address this need, recent work introduces dynamic deformable convolution to augment regular convolutions.Regular convolutions process a fixed grid of pixels across all the spatial locations in an image,  while dynamic deformable convolution may access arbitrary pixels in the image with the access pattern being input-dependent and varying with spatial location. These properties lead to inefficient memory accesses of inputs with existing hardware. \n\nIn this work, we harness the flexibility of FPGAs to develop a novel object detection pipeline with deformable convolutions. We show the speed-accuracy tradeoffs for a set of algorithm modifications including irregular-access versus limited-range and fixed-shape on a flexible hardware accelerator. We evaluate these algorithmic changes with corresponding hardware optimizations and show a 1.36x and 9.76x speedup respectively for the full and depthwise deformable convolution on hardware with minor accuracy loss. We then co-design an efficient network CoDeNet with the modified deformable convolution for object detection and quantize the network to 4-bit weights and 8-bit activations. With our high-efficiency implementation, our solution reaches 26.9 frames per second with a tiny model size of 0.76 MB while achieving 61.7 AP50 on the standard object detection dataset, Pascal VOC. \nWith our higher-accuracy implementation, our model gets to 67.1 AP50 on Pascal VOC with only 2.9 MB of parameters---20.9x smaller but 10% more accurate than Tiny-YOLO. ",
    "poster": "",
    "demo": true,
    "theme": 6,
    "photo": "https://conix.io/wp-content/uploads/photos/197.jpg",
    "video": "",
    "avideo": "",
    "advisor": "John Wawrzynek",
    "school": "University of California, Berkeley",
    "schoolshort": "Berkeley",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/15559/"
    ],
    "gdate": "2020-12-31T05:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m11db4b7fa3151049d3cdea20ea7340a6"
  },
  {
    "email": "marien@andrew.cmu.edu",
    "name": [
      "Marie Nguyen"
    ],
    "authors": "Marie Nguyen and James C. Hoe",
    "title": "Partial Reconfiguration for Design Optimization",
    "abstract": "FPGA designers have traditionally shared a similar design methodology with ASIC designers. Most notably, at design time, FPGA designers commit to a fixed allocation of logic resources to modules in a design. At runtime, some of the occupied resources could be left under-utilized due to hard-to-avoid sources of inefficiencies (e.g., operation dependencies, unbalanced pipelines). This work is relevant to applications within CONIX that (1) can benefit from FPGA acceleration and (2) are resource or device cost constrained. If mapped traditionally on the FPGA (i.e. without PR), under-utilization may result in (1) the design not running at the desired performance given an area budget, or (2) the design running at the desired performance but being too big to fit in the given area. With  partial reconfiguration (PR), FPGA resources can be re-allocated over time. Therefore, using PR, a designer can attempt to reduce slack, or under-utilization, with better time-space scheduling.\n\nIn this work, we  first introduce the concept of area-time volume to explain why PR-style designs can improve upon ASIC-style designs. We identify slack as an opportunity that can be exploited by PR-style designs. We then present a first-order analytical model to help a designer decide if a PR-style design can be beneficial. When it is the case, the model points to the most suitable PR execution strategy and provides an estimate of the improvement. The  model is validated in three case studies.\n",
    "poster": "https://www.src.org/library/publication/p101294/",
    "demo": true,
    "theme": 6,
    "photo": "https://conix.io/wp-content/uploads/photos/46.png",
    "video": "",
    "avideo": "",
    "advisor": "James Hoe",
    "school": "Carnegie Mellon University",
    "schoolshort": "CMU",
    "srcprofile": [
      "https://www.src.org/student-center/student-directory/14119/"
    ],
    "gdate": "2020-08-31T04:00:00.000Z",
    "meetlink": "https://src.webex.com/src/j.php?MTID=m69443d0eb6f0e8dd09cf8fb7c0616fcc"
  }
]
